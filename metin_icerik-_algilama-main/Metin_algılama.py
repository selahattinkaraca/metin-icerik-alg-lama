# -*- coding: utf-8 -*-
"""13_ocak_ysa.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MhRfj26De7spipcl9PCiver89-fnekIR
"""

import re
import nltk
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

bias=0.01

pd.options.display.max_colwidth = 8000
nltk.download('stopwords')
#Örnek Türkçe dokümanlar 
docs = [                
        'ilk günündeki 20 yarış heyecanlıydı, 109 puan toplayan Türkiye, 12 ülke arasında 9. oldu ve yarış tamamlandı',
        'Cortananın yeni işletim sistemi Windows 10 un önemli bir parçası olduğunu belirten Microsoft ; Google Android ve iOS cihazlarındaki Dijital',
        'Siroz hastalığı ile ilgili detaylara dikkat çekerek, sağlıklı bir karaciğere sahip olmak hastalık için',
        'ilk 4 etaptan galibiyetle ayrılan 18 yaşındaki Razgatlıoğlu, Almanya daki yarışta 3. sırayı alarak ',
        'Teknoloji devi Google, Android in MMM sürümüyle birlikte bir çok sistemsel hatasının düzeltileceğini', 
        'Hastalık çoğu kez yıllarca doğru tanı konmaması veya ciddiye alınmaması sebebi ile kısırlaştırıcı etki yapabiliyor, kronik ağrı,',
        'İrfan Can Kahveci, transferin en gözde ismi haline gelirken Galatasaray, Başakşehir le pazarlıklarını sürdürüyor. İşte Göksel Gümüşdağ - Abdurrahim Albayrak görüşmesinin detayları...',
        'ASELSAN ın Çok Maksatlı Amfibi Hücum Gemisi TCG Anadolu için geliştirdiği PİRİ Kızılötesi Arama ve Takip Sistemi nin (KATS) fabrika kabul testleri tamamlandı.',
        'Sağlık, sadece hastalık ve sakatlık durumunun olmayışı değil kişinin bedenen, ruhen ve sosyal yönden tam bir iyilik halidir.',
        'Henry Onyekuru yu Monaco dan satın alma opsiyonu ile kiralık olarak yeniden kadrosuna katan sarı-kırmızılılar, İrfan Can Kahveci için de bütün imkânlarını zorluyor.',
        'Gemiye yerleştirilen 3 sensörle 360 derece kapsama sağlayan sistem, panoramik olarak yarattığı görüntüyle farklı deniz koşullarında kullanıcıya pasif şekilde tespit ve takip imkanı veriyor.',
        'Sağlık Bakanlığınca Covid-19 salgını sürecinde hastanelerde "Aşı Uygulama Odası" oluşturulması hakkında il sağlık müdürlüklerine gönderilen yazı kapsamında, İstanbul genelindeki kamu hastaneleri ve özel hastanelerde aşı odaları hazırlandı.', 
        ' Türkiye Kupası nda Malatya ya konuk olacak Galatasaray, Youssouf Ndayishimiye için burada son kez masaya oturacak ve transferi bitirmeye çalışacak.',
        'SSB den yapılan yazılı açıklamaya göre, ROKETSAN ın ana yükleniciliğinde geliştirilecek "ORKA" ile bu alandaki dışa bağımlılık sona erecek.',  
        'Dünya Sağlık Örgütü nün 1986 yılında yayınlanan Sağlık Teşviki için Ottawa Şartı, sağlığın bir durum veya hayatın amacı değil, günlük yaşam için bir kaynak olduğunu belirtti. ',
        '1. Lig ekiplerinden Ankara Keçiörengücü, Zlatan Ibrahimovic ile paylaştığı videonun ardından ünlü futbolcunun vatandaşı Edin Hamidovici transfer ettiğini duyurdu',
        'Çaldıran Belediyesi, model uçak yapma ve model uçak uçurma kursuyla öğrencileri TEKNOFEST e hazırlıyor.',
        'Fiziksel egzersiz fiziksel zindeliği ve genel sağlık ve iyilik halini arttırır veya korumaya yardımcı olur; kasları güçlendirir ve kardiyovasküler sistemi geliştirir',
        'TFF den yapılan açıklamada, Galatasaray, Fatih Karagümrük, MKE Ankaragücü, Yukatel Denizlispor, Atakaş Hatayspor ve Büyükşehir Belediye Erzurumspor un çeşitli gerekçelerle disipline sevk edildiği belirtildi',
        'PlayStation 5in oyun diski takılamayan ve daha uygun fiyatla gelmesi beklenen dijital sürümü, yakında Türkiyede satışa çıkacak.',
        'Uyku sağlığı korumak için temel bir bileşendir. Çocuklarda uyku, büyüme ve gelişme için de hayati önem taşır.'


]        
#Dokümanların sınıfları
classes = [ 'spor', 'teknoloji',  'saglik',
           'spor','teknoloji','saglik',
           'spor','teknoloji','saglik',
           'spor','teknoloji','saglik',
           'spor','teknoloji','saglik',
           'spor','teknoloji','saglik',
           'spor','teknoloji','saglik'
           ]
sınıflar_cıktı=["spor","teknoloji","saglik"]
docs = np.array(docs)
df_docs = pd.DataFrame({'Dokuman': docs, 
                        'Sinif': classes})                  #pandas kütüphanesi ile verileri 2 boyutlu etiketlenmiş verilere çeviriyoruz.
df_docs = df_docs[['Dokuman', 'Sinif']]
print(df_docs)
print("df_docs------------------------")
WPT = nltk.WordPunctTokenizer()                             #Makine öğrenimi yapmadan önce metin içerisindeki kelimeleri uygun formata çevirmeliyiz.
print("WPT")                                                #Özel karakterler atılır, tokenlere ayrılır, noktalama işaretleri vb. kaldırılır, gereksiz kelimeler filtrelenir ve köklerine ayrılır.
stop_word_list = nltk.corpus.stopwords.words('turkish')     #NLTK kütüphanesinde tanımlı olan gereksiz kelimeler kaldırıldı.
def norm_doc(single_doc):                                   #İşlemler bu fonksiyonda yapıldı.
    #Dokümandan belirlenen özel karakterleri ve sayıları at
    single_doc = re.sub(" \d+", " ", single_doc)
    pattern = r"[{}]".format(",.;") 
    single_doc = re.sub(pattern, "", single_doc) 
    #Dokümanı küçük harflere çevir
    single_doc = single_doc.lower()
    single_doc = single_doc.strip()
    #Dokümanı token'larına ayır
    tokens = WPT.tokenize(single_doc)
    #Stop-word listesindeki kelimeler hariç al
    filtered_tokens = [token for token in tokens if token not in stop_word_list]
    #Dokümanı tekrar oluştur
    single_doc = ' '.join(filtered_tokens)
    return single_doc
norm_docs = np.vectorize(norm_doc) 
normalized_documents = norm_docs(docs)
print(normalized_documents)                        
#1.Terim Sayma Adımları
from sklearn.feature_extraction.text import CountVectorizer   #Metindeki kelimeleri vektöre çeviren BoW yaklaşımını kullanıyoruz. Bunun için CountVectorizer sınıfını import ettik.
BoW_Vector = CountVectorizer(min_df = 0., max_df = 1.)        #Bu yaklaşım kelimeleri, indisleri ve metinde kaçar defa geçtiklerini data frame olarak gösteriyor.
print("bow vektor")
#print(BoW_Vector)
BoW_Matrix = BoW_Vector.fit_transform(normalized_documents)
print("bov matrix")
#print (BoW_Matrix)
#BoW_Vector içerisindeki tüm öznitelikleri al

features = BoW_Vector.get_feature_names()
print ("features[46]:" + features[46])
print ("features[48]:" +features[48])
BoW_Matrix = BoW_Matrix.toarray()                 #BoW_Matrixi dizi haline getirdik.
#Doküman -öznitelik matrisini göster

BoW_df = pd.DataFrame(BoW_Matrix, columns = features)     #Dizi haline getirdiğimiz matrixi data frame girdisi olarak kullandık.
BoW_df                                                    #Data frame başarılı şekilde oluşturuldu fakat ağırlıklar sadece 0 veya 1.
print("bow_df-----------------")                          #Ağırlıkları önemli kılmak için TFxIdf skorlama modelini kullanıyoruz. 
print(BoW_df)                                            #Böylece ağırlık değerleri 0 ve 1 arasındaki değerler de olabiliyor.
#2.TFxIdf Hesaplama Adımları
from sklearn.feature_extraction.text import TfidfVectorizer
Tfidf_Vector = TfidfVectorizer(min_df = 0., max_df = 1., use_idf = True)          #Matrisin i. dökümanındaki j. değerin sıklığını buluyor. (Kaç defa geçiyor/Toplam kaç kelime var) ve
Tfidf_Matrix = Tfidf_Vector.fit_transform(normalized_documents)                   #ters belge sıklığı değeri bulunuyor. Bu iki değer çarpılıyor ve yeni ağırlık değeri olarak atanıyor.
Tfidf_Matrix = Tfidf_Matrix.toarray()
print(np.round(Tfidf_Matrix, 3))
#Tfidf_Vector içerisindeki tüm öznitelikleri al

features = Tfidf_Vector.get_feature_names()               #Vektör içerisindeki öznitelikler features parametresine alındı.
#Doküman - öznitelik matrisini göster                     
Tfidf_df = pd.DataFrame(np.round(Tfidf_Matrix, 3), columns = features)  #Yeni bir data frame oluşturuluyor. Ağırlık değerleri olarak TFxIdf sonuçları alınıyor.
Tfidf_df
print("ıfidfffff")
print(Tfidf_df)
dizi=[]
dizi.append(sum(Tfidf_Matrix[0]))
dizi.append(sum(Tfidf_Matrix[1]))
dizi.append(sum(Tfidf_Matrix[2]))
dizi.append(sum(Tfidf_Matrix[3]))
dizi.append(sum(Tfidf_Matrix[4]))
dizi.append(sum(Tfidf_Matrix[5]))
genel_agırlık=[]
enbuyuk=0
indis=0
for i in range(0,len(dizi)):
  if(dizi[i]>enbuyuk):
    enbuyuk=dizi[i]
    indis=i

print(classes[i])
                                              #Ağırlık değerlerinin tutulacağı diziler tanımlanıyor
spor_ağırlık=[]
genel_spor=[[],[],[],[],[],[],[]]
teknoloji_agırlık=[]
genel_teknoloji=[[],[],[],[],[],[],[]]
sağlık_ağırlık=[]
genel_sağlık=[[],[],[],[],[],[],[]]
weights=[]
cıktı_dizisi=[[1,-1,-1],[-1,1,-1],[-1,-1,1]]
y=[[0,0,0],[0,0,0],[0,0,0]]
threshold=0.5

bias=0.01
print(Tfidf_Matrix[0])
"""
for j in range(0,len(docs)):
  for i in range(0,len(Tfidf_Matrix[0])):
    genel_spor[j][i]=0
    genel_teknoloji[j][i]=0
    genel_sağlık[j][i]=0
"""
for i in range(0,len(Tfidf_Matrix[0])):
  spor_ağırlık.append(0)
  teknoloji_agırlık.append(0)
  sağlık_ağırlık.append(0)
  weights.append(0)

print("feturesss")
print(features)
print(len(features))
print(len(Tfidf_Matrix[0]))
print("Boyut==",len(Tfidf_Matrix))
dongu=0

def sum_unit_bul(weights,harfler_dizi):#ağırlık değerleriyle girdilerin çarpılıp toplamlarının elde edildiği fonksiyon
    sum_unit=0
    
    for i in range(0,len(weights)):
        sum_unit+=harfler_dizi[i]*weights[i]
    #print("sum_ınit(x*w)=="+str(sum_unit))
    return sum_unit
def weights_düzenle(t,harfler_dizi):  #Ağırlık değerlerinin güncellendiği kısım
    global weights
    global learning_rate
    
    for i in range(0, len(weights)):
        weights[i]=weights[i]+harfler_dizi[i]*t
     

g_spor_indis=0
g_teknoloki_indis=0
g_saglık_indis=0
def egit(dizi):
    k = 0
    global bias
    global cıktı_dizisi
    global g_spor_indis
    global g_teknoloki_indis
    global g_saglık_indis
    for j in range(0, 1500):
        global_delta = 0
        print("Döngü="+str(j))
        value=999
        for i in range(0, 3):
            #print(dizi[i])
            actual = cıktı_dizisi[k][i]                     # istediğimiz çıktı değeri actual değişkenine atılıyor
            sum_unit = bias + sum_unit_bul(weights, dizi[i])
            #print("k==" + str(k) + " i==" + str(i) + "bias" + str(bias) + "y[]==" + str(y) + "çıktılar[k][i]" + str(cıktı_dizisi[k][i]) + "çıktılar" + str(cıktı_dizisi))
            #print("sum unit ==>",sum_unit)
            if (sum_unit > threshold):      #value değişkenine ne atılalcağına karar veriyoruz
                value = 1
                y[k][i] = value
            elif (sum_unit <= threshold and sum_unit >= (-1 * threshold)):
                value = 0
              #  y[k][i] = value
              
            elif (sum_unit < (-1 * threshold)):
                value = -1
                y[k][i] = value
              
            #print("Value==",value)
            bias = bias + actual                                #bias değerini güncelliyoruz.    
            delta = actual - value                               #hatayı hesaplıyoruz
            global_delta = global_delta + abs(delta)            #elde ettiğimiz hatayı global bir değişkene atıyoruz
            print("Prediction :", y, "whereas actual :", cıktı_dizisi[0][i], "error", delta, "global delta", global_delta)
            weights_düzenle(delta, dizi[i])
        print("-------------------------")
        if global_delta == 0:
          #Hangi ağırlık değerine yazdırılacağını  buradaki if bloklarıyla belirliyoruz
            if (k == 0):
                for i in range(0, len(dizi[i])):
                    spor_ağırlık[i] = weights[i]
                    genel_spor[g_spor_indis].append(weights[i])                     #butun ağırlıkları tututğumuz diziye eklıyoruz
                g_spor_indis+=1                               
                #genel spor ağırlıklarına o anki ağırlığı kopyalamak için gerekli indis 
            if (k == 1):
                for i in range(0, len(dizi[i])):
                    teknoloji_agırlık[i] = weights[i]
                    genel_teknoloji[g_teknoloki_indis].append(weights[i])
                g_teknoloki_indis+=1
            if (k == 2):
                for i in range(0, len(dizi[i])):
                    sağlık_ağırlık[i] = weights[i]
                    genel_sağlık[g_saglık_indis].append(weights[i])
                g_saglık_indis+=1
            
            k+=1
        if global_delta == 0 and k == 3:
            break
son_sonuclar=[]
def hesapla(dizi):                #İhtimallerin hesaplandığı fonksiyon
    sonuc_dizi=[0,0,0]
    global son_sonuclar
    for i in range(0,len(genel_spor)):
      try:
        sonuc_dizi=[0,0,0]
        for j in range(0, len(dizi)):
            sonuc_dizi[0] += genel_spor[i][j] * dizi[j]
            sonuc_dizi[1]+= genel_teknoloji[i][j] * dizi[j]
            sonuc_dizi[2]+= genel_sağlık[i][j] * dizi[j]
        #print("sonuc_dizi")
        #print(sonuc_dizi)
        for i in range(0, 3):
            if sonuc_dizi[i] > 0:
                sonuc_dizi[i] = 1
            else:
                sonuc_dizi[i] = 0
        #print(sonuc_dizi)
        if(sum(sonuc_dizi)==1):         #tTek bir değerin 1 diğer 2 sinin 0 olup olmadığını kontrol ediyoruz
            #print("sum sonuc=",sum(sonuc_dizi))
            #print(son_sonuc)
            son_sonuclar.append(sonuc_dizi)
        
      except:
        print("An exception occurred")
        
    
       

indis=0
degismis_Tfidf_Matrix=Tfidf_Matrix
print("-------------------------")
print(degismis_Tfidf_Matrix[0])
print(degismis_Tfidf_Matrix[0][0])

for i in range(0,len(degismis_Tfidf_Matrix)):  #Matris değerlerindeki 0 değerleri yerine -1 atıyoruz
  for j in range(0,len(degismis_Tfidf_Matrix[i])):
    if(degismis_Tfidf_Matrix[i][j]==0):
      degismis_Tfidf_Matrix[i][j]=-1

print(degismis_Tfidf_Matrix)

gecici_dizi=[]
while indis<len(Tfidf_Matrix):
  gecici_dizi.append(degismis_Tfidf_Matrix[indis])
  gecici_dizi.append(degismis_Tfidf_Matrix[indis+1])
  gecici_dizi.append(degismis_Tfidf_Matrix[indis+2])
  egit(gecici_dizi)
  indis+=3
  gecici_dizi.clear()

print(spor_ağırlık)
print("------------------------------")
print(teknoloji_agırlık)
print("---------------------------")
print(sağlık_ağırlık)

#cumle='Dünya Sağlık Örgütü nün 1986 yılında yayınlanan Sağlık Teşviki için Ottawa Şartı, sağlığın bir durum veya hayatın amacı değil, günlük yaşam için bir kaynak olduğunu belirtti.'
cumle=input("Cümle girinzi=")
cumle.lower()       #Cumleyi kucuk harflere donusturuyoruz
cumle_vektor=norm_docs(cumle)       #cumlede kullanılmayan karakterler atılıyor
kelimeler=str(cumle_vektor)
kelime=kelimeler.split(" ")
print(kelime)
print(features)
kelime_matrisi=[]
#kelime matrisine 0 değerleri atılıyor
for i in range(0,len(features)):
  kelime_matrisi.append(0)
sayac=0
print("TTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT")
for i in range(0,len(features)):
  for j in range(0,len(kelime)):      #elimizdeki kelimeler kumesi olan features dei kelimelerle ele aldığımız cümlenin kelimelerini karsilastırıp eşleşme elde ediyoruz
    if kelime[j]==features[i]:
      print(kelime[j],"==",features[i])
      sayac+=1
  if(sayac==0):
    kelime_matrisi[i]=-1
  else:
    kelime_matrisi[i]=sayac
  sayac=0
print("-------------TTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT------------------------")
print(kelime_matrisi)
"""
for i in genel_sağlık:
  print(i)
print("------")
for i in genel_teknoloji:
  print(i)
for i in genel_spor:
  print(i)
"""
hesapla(kelime_matrisi)
print("-------İhtimaller-----")

son_indis=len(son_sonuclar)-1               #Ekrana  ihtimalleri yazdırıryoruz
while(0<=son_indis):
  print(str(len(son_sonuclar)-son_indis),".İhtimal=",son_sonuclar[son_indis])
  son_indis-=1